{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00212316-693f-4872-b21d-b222ebb6dd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from safetensors.torch import load_model\n",
    "import json\n",
    "\n",
    "import torch\n",
    "\n",
    "import einops\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import requests\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "from IPython.display import HTML, IFrame, clear_output, display\n",
    "#from jaxtyping import Float, Int\n",
    "\n",
    "from sae_lens import (\n",
    "    SAE,\n",
    "    ActivationsStore,\n",
    "    HookedSAETransformer,\n",
    "    LanguageModelSAERunnerConfig,\n",
    "    SAEConfig,\n",
    "    SAETrainingRunner,\n",
    "    upload_saes_to_huggingface,\n",
    ")\n",
    "from sae_lens.toolkit.pretrained_saes_directory import get_pretrained_saes_directory\n",
    "from sae_vis import SaeVisConfig, SaeVisData, SaeVisLayoutConfig\n",
    "from tabulate import tabulate\n",
    "from torch import Tensor, nn\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.nn import functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from transformer_lens import ActivationCache, HookedTransformer\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from transformer_lens.utils import get_act_name, test_prompt, to_numpy\n",
    "\n",
    "\n",
    "#sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\",)))\n",
    "#print(\"\\n\".join(sys.path))\n",
    "current_dir = os.path.dirname(os.path.abspath(\"spar_sae_circuit_sandbox.ipynb\"))\n",
    "model_dir = os.path.join(current_dir, '..') # Assuming it's one level up\n",
    "#toy_model_dir = os.path.join(current_dir, '..', 'llm_from_scratch/LLM_from_scratch/')\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "checkpoint_dir = Path('/Volumes/MacMini/gpt-circuits') / \"checkpoints\"\n",
    "gpt_dir = checkpoint_dir / \"shakespeare_64x4\"\n",
    "sae_dir = checkpoint_dir / \"standard.shakespeare_64x4\"\n",
    "\n",
    "sys.path.append(model_dir)\n",
    "#sys.path.append(toy_model_dir)\n",
    "\n",
    "from config.gpt.training import options\n",
    "from config.sae.models import sae_options\n",
    "from models.gpt import GPT\n",
    "from models.sparsified import SparsifiedGPT\n",
    "from data.tokenizers import ASCIITokenizer, TikTokenTokenizer\n",
    "\n",
    "# Loading SparsifiedGPT\n",
    "\n",
    "\n",
    "# Imports from the project\n",
    "from config.sae.models import SAEConfig\n",
    "from models.sparsified import SparsifiedGPT\n",
    "from models.gpt import GPT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65d844ae-341c-4907-b33b-2fa83e6e217d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GPT model...\n",
      "Loading SAE configuration...\n",
      "Creating SparsifiedGPT model...\n",
      "Loading SAE weights...\n"
     ]
    }
   ],
   "source": [
    "# Load GPT model\n",
    "print(\"Loading GPT model...\")\n",
    "gpt = GPT.load(gpt_dir, device=device)\n",
    "    \n",
    "# Load SAE config\n",
    "print(\"Loading SAE configuration...\")\n",
    "sae_config_dir = sae_dir / \"sae.json\"\n",
    "with open(sae_config_dir, \"r\") as f:\n",
    "    meta = json.load(f)\n",
    "config = SAEConfig(**meta)\n",
    "config.gpt_config = gpt.config\n",
    "    \n",
    "# Create model using saved config\n",
    "print(\"Creating SparsifiedGPT model...\")\n",
    "model = SparsifiedGPT(config)\n",
    "model.gpt = gpt\n",
    "    \n",
    "# Load SAE weights\n",
    "print(\"Loading SAE weights...\")\n",
    "for layer_name, module in model.saes.items():\n",
    "    weights_path = os.path.join(sae_dir, f\"sae.{layer_name}.safetensors\")\n",
    "    load_model(module, weights_path, device=device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "004210e5-abf4-44f0-9116-a79be3deb745",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils import generate\n",
    "#c_name = 'standardx8.shakespeare_64x4'\n",
    "name = 'standard.shakespeare_64x4'\n",
    "#name = 'shakespeare_64x4'\n",
    "#config = sae_options[c_name]\n",
    "\n",
    "#model = SparsifiedGPT(config)\n",
    "#model_path = os.path.join(\"../checkpoints\", name)\n",
    "#model = model.load(model_path, device=config.device)\n",
    "\n",
    "#load tokenizer\n",
    "tokenizer = ASCIITokenizer() if \"shake\" in name else TikTokenTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df68d384-4781-4d04-b748-dad500984e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, tokenizer, prompt, max_length=50, temperature=0.7) -> str:\n",
    "    \"\"\"\n",
    "    Generate text from a prompt using the model\n",
    "    \"\"\"\n",
    "    tokens = tokenizer.encode(prompt)\n",
    "    tokens = torch.Tensor(tokens).long().unsqueeze(0)\n",
    "    \n",
    "    for _ in range(max_length):\n",
    "        logits = model(tokens).logits[0][-1]\n",
    "        probs = torch.softmax(logits / temperature, dim=-1)\n",
    "        #next_token = torch.multinomial(probs, num_samples=1)\n",
    "        next_token = torch.argmax(probs, keepdim=True)\n",
    "        \n",
    "        tokens = torch.cat([tokens.squeeze(0), next_token], dim=-1).unsqueeze(0)\n",
    "        \n",
    "    #return tokenizer.decode_sequence(tokens[0].tolist())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44fdabca-2880-4642-a356-7b930df485e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"His name is Licio, born in Mantua.\"\n",
    "tokens = tokenizer.encode(prompt)\n",
    "tokens = torch.Tensor(tokens).long().unsqueeze(0)\n",
    "with torch.no_grad():\n",
    "    model_output = model(tokens)\n",
    "\n",
    "# Generate output text/tokens using \"generate\" function\n",
    "#output = generate(model, tokenizer, prompt, max_length=1)\n",
    "#print(output)\n",
    "#print(tokenizer.decode_sequence(output[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "da75bacb-c66d-4e92-b616-277abf7972a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with model.use_saes():\n",
    "    #output_sae = model(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c4291c1-f271-449b-b95c-9298c25dd42a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparsifiedGPTOutput(logits=tensor([[[-15.0021, -14.9872, -14.9872,  ..., -15.0066, -15.0015, -14.9803],\n",
       "         [-20.9965, -20.9861, -21.0117,  ..., -20.9863, -20.9932, -20.9777],\n",
       "         [-13.5827, -13.5573, -13.5960,  ..., -13.5951, -13.5750, -13.5636],\n",
       "         ...,\n",
       "         [-15.3942, -15.4329, -15.4454,  ..., -15.4078, -15.4222, -15.4405],\n",
       "         [ -9.6964,  -9.7105,  -9.7095,  ...,  -9.7102,  -9.6881,  -9.7186],\n",
       "         [-13.8675, -13.8698, -13.8927,  ..., -13.8691, -13.8846, -13.8751]]]), cross_entropy_loss=None, activations={0: tensor([[[-0.3428, -0.0691,  0.1505,  ..., -0.3408, -0.0127,  0.1800],\n",
       "         [ 0.0057, -0.0554, -0.2171,  ...,  0.0312, -0.0692,  0.2164],\n",
       "         [ 0.0641,  0.1122,  0.0556,  ..., -0.0218, -0.1222,  0.0047],\n",
       "         ...,\n",
       "         [ 0.0346, -0.2275,  0.0020,  ..., -0.1253, -0.0569,  0.1417],\n",
       "         [ 0.0639, -0.1175,  0.1612,  ...,  0.0462,  0.1182, -0.0252],\n",
       "         [ 0.0842, -0.0115,  0.0195,  ...,  0.0756, -0.0850,  0.0403]]]), 1: tensor([[[-3.2133e-01,  6.5248e-02, -2.2508e-01,  ..., -4.4822e-01,\n",
       "          -3.9322e-02,  2.8073e-01],\n",
       "         [-7.1790e-02, -7.8701e-02, -5.3191e-01,  ..., -1.9740e-01,\n",
       "          -9.6521e-02,  2.6091e-01],\n",
       "         [ 7.4400e-02,  6.1041e-02, -2.1346e-01,  ..., -1.7184e-01,\n",
       "          -1.7406e-01,  1.9678e-02],\n",
       "         ...,\n",
       "         [-9.3294e-03, -2.1595e-01, -9.7305e-02,  ..., -1.1933e-01,\n",
       "          -5.4862e-02,  2.7409e-01],\n",
       "         [ 6.0450e-02, -1.2006e-01,  3.4969e-02,  ...,  5.2549e-05,\n",
       "           1.9466e-01,  5.6659e-03],\n",
       "         [ 2.1887e-02,  3.1896e-02, -8.1001e-02,  ...,  6.9640e-02,\n",
       "          -6.7329e-02,  9.6342e-02]]]), 2: tensor([[[-0.5486,  0.2655, -0.1076,  ...,  0.0519, -0.0006,  0.2773],\n",
       "         [-0.2326,  0.2165, -0.2508,  ...,  0.1841, -0.1032,  0.1053],\n",
       "         [-0.1775,  0.1848, -0.0585,  ...,  0.0597, -0.2780, -0.2030],\n",
       "         ...,\n",
       "         [-0.0495, -0.1098, -0.1659,  ..., -0.3026, -0.3052,  0.1920],\n",
       "         [ 0.0540, -0.0631, -0.0527,  ..., -0.2924,  0.0856, -0.3510],\n",
       "         [ 0.1094,  0.0632, -0.2176,  ..., -0.3851, -0.2335,  0.0104]]]), 3: tensor([[[-0.7462, -0.0695, -0.3647,  ..., -0.0865,  0.0330,  0.1761],\n",
       "         [-0.3555, -0.1499,  0.0641,  ..., -0.2709,  0.2856, -0.2536],\n",
       "         [-0.2554, -0.3157, -0.1771,  ..., -0.0513, -0.3389, -0.1736],\n",
       "         ...,\n",
       "         [ 0.3235, -0.0918, -0.0557,  ..., -0.1747, -0.1805,  0.2282],\n",
       "         [-0.2007, -0.3063,  0.0081,  ..., -0.0026, -0.1826,  0.4150],\n",
       "         [-0.0604,  0.1540, -0.0186,  ..., -0.4254, -0.0519, -0.1059]]]), 4: tensor([[[-3.0201e-01,  3.3896e-01,  1.4408e-01,  ...,  2.4094e-01,\n",
       "          -1.1439e-01,  2.9206e-06],\n",
       "         [-1.5573e-01,  8.7727e-02, -9.0891e-02,  ...,  7.2776e-02,\n",
       "           2.4198e-01, -1.9628e-01],\n",
       "         [ 3.8198e-01,  4.3152e-01,  1.2116e-01,  ..., -9.6832e-02,\n",
       "          -1.6831e-01, -1.3048e-01],\n",
       "         ...,\n",
       "         [ 5.4541e-01, -2.2544e-01,  2.4090e-01,  ..., -1.9719e-01,\n",
       "           3.6346e-01,  3.0628e-01],\n",
       "         [-6.8317e-01,  5.1614e-01, -1.3301e-01,  ...,  5.9246e-01,\n",
       "          -1.7644e-01,  2.2248e-02],\n",
       "         [-6.7528e-01,  2.8513e-01, -1.4769e-01,  ..., -1.6670e-01,\n",
       "          -3.4831e-01, -3.2924e-01]]])}, ce_loss_increases=None, compound_ce_loss_increase=None, sae_loss_components={}, feature_magnitudes={0: tensor([[[0.0000, 0.3404, 0.0340,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.1793, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]), 1: tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.1419,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0691,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]), 2: tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.2582],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0820],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]), 3: tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1183, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1250, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0198, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]), 4: tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0085, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.1773, 0.4878, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]])}, reconstructed_activations={0: tensor([[[-0.6567, -1.1425, -0.2917,  ..., -0.9906, -0.5973,  0.6411],\n",
       "         [-0.0714, -0.4891, -0.6012,  ...,  0.1781,  0.1766,  0.1610],\n",
       "         [-0.0762, -0.3683, -0.5319,  ...,  0.2950, -0.5379,  0.1650],\n",
       "         ...,\n",
       "         [ 0.0464, -0.0760,  0.0087,  ..., -0.1609,  0.0591,  0.0942],\n",
       "         [-0.0459, -0.2852, -0.2781,  ..., -0.3070,  0.1819, -0.0868],\n",
       "         [-0.0692, -0.1445,  0.0468,  ...,  0.0657, -0.1304,  0.2045]]]), 1: tensor([[[-2.4643e-01, -1.4709e+00, -4.7747e-01,  ..., -9.8736e-01,\n",
       "           3.4631e-01,  2.2696e-01],\n",
       "         [ 1.1334e-01, -1.3580e+00, -8.7638e-01,  ..., -1.9255e-01,\n",
       "          -2.6741e-03,  6.4788e-01],\n",
       "         [ 4.6933e-01, -9.4564e-01, -4.5297e-01,  ..., -1.8728e-01,\n",
       "          -1.7505e-01,  1.2616e+00],\n",
       "         ...,\n",
       "         [-7.5736e-01, -1.0365e+00,  3.5906e-01,  ..., -4.5863e-01,\n",
       "           4.3124e-01, -2.2911e+00],\n",
       "         [-9.1678e-01, -1.6572e+00,  5.6890e-01,  ..., -4.7399e-01,\n",
       "           7.9355e-01, -3.0093e+00],\n",
       "         [-2.8082e-01, -8.1813e-01,  3.0884e-01,  ..., -1.1239e-01,\n",
       "           1.2801e-01, -1.5561e+00]]]), 2: tensor([[[-1.8836e-01,  6.7530e-02, -2.1741e-01,  ..., -3.6783e-01,\n",
       "          -2.8680e-01,  5.2693e-01],\n",
       "         [-3.2186e-01,  4.6257e-02, -4.8338e-01,  ..., -2.6000e-02,\n",
       "          -2.7437e-01,  3.9762e-01],\n",
       "         [-1.8867e-01, -2.0880e-03, -5.4255e-03,  ..., -1.3322e-01,\n",
       "          -3.0540e-01, -2.3125e-02],\n",
       "         ...,\n",
       "         [-1.3254e-01,  8.5846e-02,  1.4890e-01,  ..., -6.7072e-02,\n",
       "          -2.6820e-01,  2.3464e-01],\n",
       "         [ 8.1951e-02,  1.1998e-01, -2.5647e-01,  ..., -1.3568e-01,\n",
       "          -1.3764e-01,  2.2849e-01],\n",
       "         [ 1.1256e-01,  1.4082e-01,  4.9983e-04,  ..., -3.0497e-01,\n",
       "           1.7374e-02, -3.6851e-02]]]), 3: tensor([[[-0.3948, -0.0801, -0.3471,  ...,  0.2716,  0.2840,  0.3945],\n",
       "         [-0.1950, -0.3030,  0.0198,  ..., -0.3754,  0.4161, -0.3268],\n",
       "         [-0.2182, -0.0240, -0.1611,  ..., -0.0889, -0.2458, -0.2639],\n",
       "         ...,\n",
       "         [ 0.0083,  0.0321,  0.0940,  ...,  0.0392, -0.1864,  0.0965],\n",
       "         [-0.0958, -0.0785,  0.1065,  ...,  0.0202, -0.1639,  0.0627],\n",
       "         [-0.0383,  0.1496, -0.1424,  ..., -0.3950, -0.1146, -0.3634]]]), 4: tensor([[[ 0.0962,  0.1982,  0.2140,  ...,  0.1126, -0.1331, -0.1860],\n",
       "         [-0.0198, -0.0695, -0.0289,  ...,  0.1214,  0.0292, -0.2160],\n",
       "         [-0.0786,  0.0880,  0.0026,  ...,  0.0390, -0.2098, -0.0991],\n",
       "         ...,\n",
       "         [ 0.1325, -0.3554, -0.2622,  ..., -0.3388,  0.2621, -0.0627],\n",
       "         [-0.8577,  0.9978, -0.0740,  ...,  0.7672, -0.4945, -0.2135],\n",
       "         [ 0.2388,  0.7876, -0.1493,  ..., -0.2469,  0.0829, -1.3708]]])})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6c10923-72e3-4697-839a-301e038d3eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature layers\n",
    "feat_layer0 = model_output.feature_magnitudes[0].squeeze(0)\n",
    "feat_layer1 = model_output.feature_magnitudes[1].squeeze(0)\n",
    "feat_layer2 = model_output.feature_magnitudes[2].squeeze(0)\n",
    "feat_layer3 = model_output.feature_magnitudes[3].squeeze(0)\n",
    "feat_layer4 = model_output.feature_magnitudes[4].squeeze(0)\n",
    "\n",
    "#minimum value a feature can be considered \"active\"\n",
    "feat_threshold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5105ff4-c31a-4f7f-8923-15566bd0181a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 512])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_product4 = einops.einsum(feat_layer3, feat_layer4, \"token act1, token act2 -> token act1 act2\")\n",
    "feat_product4[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54f98157",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.zeros(feat_product4[-1].shape)\n",
    "mask[torch.where(feat_product4[-1] > feat_threshold)] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059d701c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34905bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparsifiedGPT(\n",
       "  (gpt): GPT(\n",
       "    (transformer): ModuleDict(\n",
       "      (wte): Embedding(128, 64)\n",
       "      (wpe): Embedding(128, 64)\n",
       "      (h): ModuleList(\n",
       "        (0-3): 4 x Block(\n",
       "          (ln_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): CausalSelfAttention(\n",
       "            (c_attn): Linear(in_features=64, out_features=192, bias=True)\n",
       "            (c_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Linear(in_features=64, out_features=256, bias=True)\n",
       "            (gelu): GELU(approximate='tanh')\n",
       "            (c_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=64, out_features=128, bias=False)\n",
       "  )\n",
       "  (saes): ModuleDict(\n",
       "    (0): StandardSAE()\n",
       "    (1): StandardSAE()\n",
       "    (2): StandardSAE()\n",
       "    (3): StandardSAE()\n",
       "    (4): StandardSAE()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8a17bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardSAE()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.saes['0']()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3882fb0d-2053-407d-a7c4-b8d8d57625af",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'SparsifiedGPT' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model[:\u001b[38;5;241m3\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'SparsifiedGPT' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Store the output of a specific layer\n",
    "intermediate_outputs = {}\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    intermediate_outputs['target_layer'] = output\n",
    "\n",
    "# Register the hook on the layer you want\n",
    "model.layer3.register_forward_hook(hook_fn)\n",
    "\n",
    "# Run the full model\n",
    "_ = model(input_data)\n",
    "\n",
    "# Access the intermediate output\n",
    "partial_output = intermediate_outputs['target_layer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e5b4d763-28a9-4ff5-9e0d-0ce89a064f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the prompts that return the correct tokens\n",
    "double_newline_prompts = torch.load('double_newline_prompts.pt', weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "692f8b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def explore_sae_connections_sparsity(model, input_data, layer_i=0, layer_j=1, \n",
    "                                    pruning_fractions=np.linspace(0, 0.95, 20),\n",
    "                                    pruning_methods=['magnitude', 'random'],\n",
    "                                    num_trials=5):\n",
    "    \"\"\"\n",
    "    Explore sparsity of connections between adjacent SAE layers by pruning \n",
    "    connections and measuring impact on output logits.\n",
    "    \n",
    "    Args:\n",
    "        model: SparsifiedGPT model\n",
    "        input_data: Input tensor to process\n",
    "        layer_i, layer_j: Indices of adjacent SAE layers to analyze\n",
    "        pruning_fractions: List of pruning fractions to test\n",
    "        pruning_methods: List of pruning methods to use\n",
    "        num_trials: Number of trials for random pruning\n",
    "    \"\"\"\n",
    "    # Get baseline activations and logits\n",
    "    with torch.no_grad():\n",
    "        baseline_output = model(input_data)\n",
    "    \n",
    "    baseline_logits = baseline_output.logits\n",
    "    feat_layer_i = baseline_output.feature_magnitudes[layer_i].squeeze(0)  # Shape: (H, W_i)\n",
    "    feat_layer_j = baseline_output.feature_magnitudes[layer_j].squeeze(0)  # Shape: (H, W_j)\n",
    "    \n",
    "    # Compute connection strengths for each position in H\n",
    "    # For each h, compute outer product between feat_layer_i[h] and feat_layer_j[h]\n",
    "    # Shape: (H, W_i, W_j)\n",
    "    H, W_i = feat_layer_i.shape\n",
    "    _, W_j = feat_layer_j.shape\n",
    "    \n",
    "    # Use einsum for outer product while preserving H dimension\n",
    "    connection_strengths = torch.einsum('hw,hv->hwv', feat_layer_i, feat_layer_j)\n",
    "    \n",
    "    # Results storage\n",
    "    results = {method: {'kl_divs': [], 'logit_diffs': []} for method in pruning_methods}\n",
    "    \n",
    "    # For each pruning method and fraction, patch and measure impact\n",
    "    for method in pruning_methods:\n",
    "        all_kl_divs = []\n",
    "        all_logit_diffs = []\n",
    "        \n",
    "        for fraction in pruning_fractions:\n",
    "            kl_divs_trials = []\n",
    "            logit_diffs_trials = []\n",
    "            \n",
    "            # Multiple trials for random pruning\n",
    "            trials = num_trials if method == 'random' else 1\n",
    "            \n",
    "            for trial in range(trials):\n",
    "                # Create pruning mask with same shape as connection_strengths\n",
    "                mask = torch.ones_like(connection_strengths)\n",
    "                \n",
    "                if fraction > 0:\n",
    "                    if method == 'magnitude':\n",
    "                        # Prune weakest connections across all positions\n",
    "                        flat_strengths = connection_strengths.abs().flatten()\n",
    "                        num_to_prune = int(fraction * flat_strengths.numel())\n",
    "                        threshold = torch.sort(flat_strengths)[0][num_to_prune]\n",
    "                        mask = (connection_strengths.abs() > threshold).float()\n",
    "                    elif method == 'random':\n",
    "                        # Randomly prune connections\n",
    "                        num_to_prune = int(fraction * mask.numel())\n",
    "                        prune_indices = torch.randperm(mask.numel())[:num_to_prune]\n",
    "                        mask.view(-1)[prune_indices] = 0\n",
    "                \n",
    "                # Step 4: Create patched features for layer_j\n",
    "                def patch_hook(module, input, output):\n",
    "                    # Get activations from layer_i\n",
    "                    layer_i_activations = output.feature_magnitudes[layer_i]  # (1, H, W_i)\n",
    "                    \n",
    "                    # Original layer_j activations\n",
    "                    orig_layer_j = output.feature_magnitudes[layer_j]  # (1, H, W_j)\n",
    "                    \n",
    "                    # Create patched layer_j activations based on masked connections\n",
    "                    patched_layer_j = torch.zeros_like(orig_layer_j)\n",
    "                    \n",
    "                    # For each position h\n",
    "                    for h in range(H):\n",
    "                        # Get feature vectors at position h\n",
    "                        feat_i_h = layer_i_activations[0, h]  # (W_i)\n",
    "                        \n",
    "                        # Apply masked connections to compute patched layer_j at position h\n",
    "                        # For each feature in layer_j, sum contributions from all features in layer_i\n",
    "                        for w_i in range(W_i):\n",
    "                            for w_j in range(W_j):\n",
    "                                if mask[h, w_i, w_j] > 0:\n",
    "                                    # If connection exists, propagate activation\n",
    "                                    patched_layer_j[0, h, w_j] += feat_i_h[w_i] * feat_layer_j[h, w_j] / feat_layer_i[h, w_i]\n",
    "                    \n",
    "                    # Replace layer_j activations\n",
    "                    output.feature_magnitudes[layer_j] = patched_layer_j\n",
    "                    return output\n",
    "                \n",
    "                # Register the hook\n",
    "                hook_handle = model.register_forward_hook(patch_hook)\n",
    "                \n",
    "                # Run patched forward pass\n",
    "                with torch.no_grad():\n",
    "                    patched_output = model(input_data)\n",
    "                \n",
    "                # Remove the hook\n",
    "                hook_handle.remove()\n",
    "                \n",
    "                # Measure impact on logits\n",
    "                patched_logits = patched_output.logits\n",
    "                \n",
    "                # KL divergence between original and patched logits\n",
    "                kl_div = torch.nn.functional.kl_div(\n",
    "                    torch.log_softmax(patched_logits, dim=-1),\n",
    "                    torch.softmax(baseline_logits, dim=-1),\n",
    "                    reduction='batchmean'\n",
    "                )\n",
    "                \n",
    "                # L2 distance between logits\n",
    "                logit_diff = torch.norm(patched_logits - baseline_logits)\n",
    "                \n",
    "                kl_divs_trials.append(kl_div.item())\n",
    "                logit_diffs_trials.append(logit_diff.item())\n",
    "            \n",
    "            # Average results across trials\n",
    "            all_kl_divs.append(np.mean(kl_divs_trials))\n",
    "            all_logit_diffs.append(np.mean(logit_diffs_trials))\n",
    "        \n",
    "        results[method]['kl_divs'] = all_kl_divs\n",
    "        results[method]['logit_diffs'] = all_logit_diffs\n",
    "    \n",
    "    # Step 5: Analyze and visualize results\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    for method in pruning_methods:\n",
    "        plt.plot(pruning_fractions, results[method]['kl_divs'], label=method)\n",
    "    plt.xlabel('Pruning Fraction')\n",
    "    plt.ylabel('KL Divergence')\n",
    "    plt.title(f'Impact of Pruning SAE Connections (Layers {layer_i}->{layer_j})')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    for method in pruning_methods:\n",
    "        plt.plot(pruning_fractions, results[method]['logit_diffs'], label=method)\n",
    "    plt.xlabel('Pruning Fraction')\n",
    "    plt.ylabel('Logit L2 Distance')\n",
    "    plt.title('Change in Output Logits')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Visualize connection strength distribution\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.hist(connection_strengths.abs().flatten().cpu().numpy(), bins=50)\n",
    "    plt.xlabel('Connection Strength (Absolute Value)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Connection Strengths')\n",
    "    \n",
    "    # Visualize connection matrix\n",
    "    plt.subplot(2, 2, 4)\n",
    "    avg_conn = connection_strengths.abs().mean(dim=0).cpu()  # Average across H\n",
    "    plt.imshow(avg_conn, cmap='viridis')\n",
    "    plt.colorbar(label='Average Strength')\n",
    "    plt.xlabel(f'Features in Layer {layer_j}')\n",
    "    plt.ylabel(f'Features in Layer {layer_i}')\n",
    "    plt.title('Average Connection Strength Matrix')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return results, connection_strengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9f88c69",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m input_data \u001b[38;5;241m=\u001b[39m tokens\n\u001b[0;32m----> 2\u001b[0m results, connection_strengths \u001b[38;5;241m=\u001b[39m explore_sae_connections_sparsity(\n\u001b[1;32m      3\u001b[0m     model, input_data, \n\u001b[1;32m      4\u001b[0m     layer_i\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, layer_j\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      5\u001b[0m     pruning_fractions\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;241m0.99\u001b[39m],\n\u001b[1;32m      6\u001b[0m     pruning_methods\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmagnitude\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      7\u001b[0m     num_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      8\u001b[0m )\n",
      "Cell \u001b[0;32mIn[28], line 104\u001b[0m, in \u001b[0;36mexplore_sae_connections_sparsity\u001b[0;34m(model, input_data, layer_i, layer_j, pruning_fractions, pruning_methods, num_trials)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# Run patched forward pass\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 104\u001b[0m     patched_output \u001b[38;5;241m=\u001b[39m model(input_data)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Remove the hook\u001b[39;00m\n\u001b[1;32m    107\u001b[0m hook_handle\u001b[38;5;241m.\u001b[39mremove()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1844\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[1;32m   1843\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1846\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[1;32m   1847\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[1;32m   1848\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[1;32m   1849\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1803\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1801\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, args, kwargs, result)\n\u001b[1;32m   1802\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1803\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, args, result)\n\u001b[1;32m   1805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1806\u001b[0m     result \u001b[38;5;241m=\u001b[39m hook_result\n",
      "Cell \u001b[0;32mIn[28], line 93\u001b[0m, in \u001b[0;36mexplore_sae_connections_sparsity.<locals>.patch_hook\u001b[0;34m(module, input, output)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m w_j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(W_j):\n\u001b[1;32m     91\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m mask[h, w_i, w_j] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     92\u001b[0m                 \u001b[38;5;66;03m# If connection exists, propagate activation\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m                 patched_layer_j[\u001b[38;5;241m0\u001b[39m, h, w_j] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m feat_i_h[w_i] \u001b[38;5;241m*\u001b[39m feat_layer_j[h, w_j] \u001b[38;5;241m/\u001b[39m feat_layer_i[h, w_i]\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Replace layer_j activations\u001b[39;00m\n\u001b[1;32m     96\u001b[0m output\u001b[38;5;241m.\u001b[39mfeature_magnitudes[layer_j] \u001b[38;5;241m=\u001b[39m patched_layer_j\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_data = tokens\n",
    "results, connection_strengths = explore_sae_connections_sparsity(\n",
    "    model, input_data, \n",
    "    layer_i=0, layer_j=1,\n",
    "    pruning_fractions=[0, 0.9, 0.99],\n",
    "    pruning_methods=['magnitude'],\n",
    "    num_trials=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "852ea2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Make sure input data is on GPU for each analysis\n",
    "input_data = input_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4bcb57f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_sae_connection_analysis(model, input_data, layer_i=0, layer_j=1):\n",
    "    \"\"\"Simplified analysis focusing on just key pruning levels\"\"\"\n",
    "    \n",
    "    # Get baseline\n",
    "    with torch.no_grad():\n",
    "        baseline_output = model(input_data)\n",
    "    \n",
    "    baseline_logits = baseline_output.logits\n",
    "    feat_layer_i = baseline_output.feature_magnitudes[layer_i].squeeze(0)\n",
    "    feat_layer_j = baseline_output.feature_magnitudes[layer_j].squeeze(0)\n",
    "    \n",
    "    # Compute connection matrix\n",
    "    connection_strengths = torch.einsum('hw,hv->hwv', feat_layer_i, feat_layer_j)\n",
    "    \n",
    "    # Just test two pruning levels (90% and 99%)\n",
    "    results = {}\n",
    "    \n",
    "    for pruning_frac in [0.9, 0.99]:\n",
    "        # Create mask for magnitude pruning\n",
    "        flat_strengths = connection_strengths.abs().flatten()\n",
    "        num_to_prune = int(pruning_frac * flat_strengths.numel())\n",
    "        threshold = torch.sort(flat_strengths)[0][num_to_prune]\n",
    "        mask = (connection_strengths.abs() > threshold).float()\n",
    "        \n",
    "        # Simple intervention with masked connections\n",
    "        def intervention_hook(module, input, output):\n",
    "            # Simplified patching logic\n",
    "            return patched_output\n",
    "            \n",
    "        # Run intervened forward pass\n",
    "        hook_handle = model.register_forward_hook(intervention_hook)\n",
    "        with torch.no_grad():\n",
    "            patched_output = model(input_data)\n",
    "        hook_handle.remove()\n",
    "        \n",
    "        # Calculate simple metric like L2 distance\n",
    "        logit_diff = torch.norm(patched_output.logits - baseline_logits)\n",
    "        results[pruning_frac] = logit_diff.item()\n",
    "    \n",
    "    # Just print results instead of visualizing\n",
    "    print(f\"Pruning 90%: Logit diff = {results[0.9]}\")\n",
    "    print(f\"Pruning 99%: Logit diff = {results[0.99]}\")\n",
    "    \n",
    "    return results, connection_strengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2defc1d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "cannot access free variable 'patched_output' where it is not associated with a value in enclosing scope",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results, connection_strengths \u001b[38;5;241m=\u001b[39m quick_sae_connection_analysis(model, input_data,\n\u001b[1;32m      2\u001b[0m                                                               layer_i\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m      3\u001b[0m                                                               layer_j\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[35], line 33\u001b[0m, in \u001b[0;36mquick_sae_connection_analysis\u001b[0;34m(model, input_data, layer_i, layer_j)\u001b[0m\n\u001b[1;32m     31\u001b[0m hook_handle \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mregister_forward_hook(intervention_hook)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 33\u001b[0m     patched_output \u001b[38;5;241m=\u001b[39m model(input_data)\n\u001b[1;32m     34\u001b[0m hook_handle\u001b[38;5;241m.\u001b[39mremove()\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Calculate simple metric like L2 distance\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1844\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[1;32m   1843\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1846\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[1;32m   1847\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[1;32m   1848\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[1;32m   1849\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1803\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1801\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, args, kwargs, result)\n\u001b[1;32m   1802\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1803\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, args, result)\n\u001b[1;32m   1805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1806\u001b[0m     result \u001b[38;5;241m=\u001b[39m hook_result\n",
      "Cell \u001b[0;32mIn[35], line 28\u001b[0m, in \u001b[0;36mquick_sae_connection_analysis.<locals>.intervention_hook\u001b[0;34m(module, input, output)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mintervention_hook\u001b[39m(module, \u001b[38;5;28minput\u001b[39m, output):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Simplified patching logic\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m patched_output\n",
      "\u001b[0;31mNameError\u001b[0m: cannot access free variable 'patched_output' where it is not associated with a value in enclosing scope"
     ]
    }
   ],
   "source": [
    "results, connection_strengths = quick_sae_connection_analysis(model, input_data,\n",
    "                                                              layer_i=0,\n",
    "                                                              layer_j=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eaac57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
