{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "00212316-693f-4872-b21d-b222ebb6dd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch as t\n",
    "\n",
    "import einops\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import requests\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "from IPython.display import HTML, IFrame, clear_output, display\n",
    "#from jaxtyping import Float, Int\n",
    "\n",
    "from sae_lens import (\n",
    "    SAE,\n",
    "    ActivationsStore,\n",
    "    HookedSAETransformer,\n",
    "    LanguageModelSAERunnerConfig,\n",
    "    SAEConfig,\n",
    "    SAETrainingRunner,\n",
    "    upload_saes_to_huggingface,\n",
    ")\n",
    "from sae_lens.toolkit.pretrained_saes_directory import get_pretrained_saes_directory\n",
    "from sae_vis import SaeVisConfig, SaeVisData, SaeVisLayoutConfig\n",
    "from tabulate import tabulate\n",
    "from torch import Tensor, nn\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.nn import functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from transformer_lens import ActivationCache, HookedTransformer\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from transformer_lens.utils import get_act_name, test_prompt, to_numpy\n",
    "\n",
    "device = t.device(\"mps\" if t.backends.mps.is_available() else \"cuda\" if t.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d844ae-341c-4907-b33b-2fa83e6e217d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "004210e5-abf4-44f0-9116-a79be3deb745",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\",)))\n",
    "#print(\"\\n\".join(sys.path))\n",
    "# %%\n",
    "current_dir = os.path.dirname(os.path.abspath(\"spar_sae_circuit_sandbox.ipynb\"))\n",
    "model_dir = os.path.join(current_dir, '..') # Assuming it's one level up\n",
    "#toy_model_dir = os.path.join(current_dir, '..', 'llm_from_scratch/LLM_from_scratch/')\n",
    "\n",
    "sys.path.append(model_dir)\n",
    "#sys.path.append(toy_model_dir)\n",
    "\n",
    "from config.gpt.training import options\n",
    "from config.sae.models import sae_options\n",
    "from models.gpt import GPT\n",
    "from models.sparsified import SparsifiedGPT\n",
    "from data.tokenizers import ASCIITokenizer, TikTokenTokenizer\n",
    "\n",
    "#from utils import generate\n",
    "c_name = 'standardx8.shakespeare_64x4'\n",
    "name = 'standard.shakespeare_64x4'\n",
    "#name = 'shakespeare_64x4'\n",
    "config = sae_options[c_name]\n",
    "\n",
    "model = SparsifiedGPT(config)\n",
    "model_path = os.path.join(\"../checkpoints\", name)\n",
    "model = model.load(model_path, device=config.device)\n",
    "\n",
    "tokenizer = ASCIITokenizer() if \"shake\" in name else TikTokenTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "df68d384-4781-4d04-b748-dad500984e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, tokenizer, prompt, max_length=50, temperature=0.7) -> str:\n",
    "    \"\"\"\n",
    "    Generate text from a prompt using the model\n",
    "    \"\"\"\n",
    "    tokens = tokenizer.encode(prompt)\n",
    "    tokens = torch.Tensor(tokens).long().unsqueeze(0)\n",
    "    \n",
    "    for _ in range(max_length):\n",
    "        logits = model(tokens).logits[0][-1]\n",
    "        probs = torch.softmax(logits / temperature, dim=-1)\n",
    "        #next_token = torch.multinomial(probs, num_samples=1)\n",
    "        next_token = torch.argmax(probs, keepdim=True)\n",
    "        \n",
    "        tokens = torch.cat([tokens.squeeze(0), next_token], dim=-1).unsqueeze(0)\n",
    "        \n",
    "    return tokenizer.decode_sequence(tokens[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "44fdabca-2880-4642-a356-7b930df485e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's done is the seal to the sea of the sea\n",
      "That should be the strike of the seather of the seat,\n",
      "And therefore t\n"
     ]
    }
   ],
   "source": [
    "output = generate(model, tokenizer, \"What's done is \", temperature=1., max_length=100)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d78154-3a77-4783-a32d-515e925f5ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "9751fe8b-21f1-47a5-a49d-14bf4eeecf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_prompt = \"a\"\n",
    "tokens = tokenizer.encode(random_prompt)\n",
    "tokens = torch.Tensor(tokens).long().unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "9eedb462-1b42-4487-8f7b-0f8ab303177d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "da75bacb-c66d-4e92-b616-277abf7972a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with model.use_saes():\n",
    "    #output_sae = model(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "f90ec079-e282-4026-bcde-23fa55a30e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['logits', 'cross_entropy_loss', 'activations', 'ce_loss_increases', 'compound_ce_loss_increase', 'sae_loss_components', 'feature_magnitudes', 'reconstructed_activations'])"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(output).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "e187ab64-b0c9-4e32-8858-747b417d8de0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 64])"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.activations[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "1c4291c1-f271-449b-b95c-9298c25dd42a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 512])"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.feature_magnitudes[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "f6c10923-72e3-4697-839a-301e038d3eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature layers\n",
    "feat_layer0 = output.feature_magnitudes[0].squeeze(0)\n",
    "feat_layer1 = output.feature_magnitudes[1].squeeze(0)\n",
    "feat_layer2 = output.feature_magnitudes[2].squeeze(0)\n",
    "feat_layer3 = output.feature_magnitudes[3].squeeze(0)\n",
    "feat_layer4 = output.feature_magnitudes[4].squeeze(0)\n",
    "\n",
    "#minimum value a feature can be considered \"active\"\n",
    "feat_threshold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "c5105ff4-c31a-4f7f-8923-15566bd0181a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7])"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(feat_layer0 > feat_threshold)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3882fb0d-2053-407d-a7c4-b8d8d57625af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e86e8e-a667-4e5b-ae8e-b1bd7681ffe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba8b2ce-2300-4a6f-9fcf-462836348a26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaa7bcc-6a93-4cc4-b401-59ede1c00e95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
